{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Metal Band Logo Identifier\n",
        "\n",
        "This script is the final step of my band logo identifier app. If you hit 'run all' and go down to the bottom, there will be a link to a Gradio applet where you can upload an image of a band logo, and my model will try to guess what it is. It works by guessing the three bands it deems 'closest' to the input logo, bands on cosine similarity; the bands are listed in order of likelihood.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1uK2TdenSsdZ1rBB334NJ3U0kZidgbfII)\n",
        "\n"
      ],
      "metadata": {
        "id": "M22k92Xm8d7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary packages\n",
        "import os\n",
        "import io\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "from torchvision.transforms import v2\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import display, Image as IPImage, clear_output"
      ],
      "metadata": {
        "id": "pHeZwj_BSbZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agqN47j7NAJF"
      },
      "outputs": [],
      "source": [
        "# path to my model files\n",
        "model_dir = \"/content/drive/MyDrive/Logos/final_model\"\n",
        "\n",
        "# load the model and processor from the directory\n",
        "model = CLIPModel.from_pretrained(model_dir)\n",
        "processor = CLIPProcessor.from_pretrained(model_dir)\n",
        "\n",
        "# send the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# initialize the processor (this handles image and text preprocessing for CLIP)\n",
        "processor = CLIPProcessor.from_pretrained(model_dir)\n",
        "\n",
        "def get_image_embedding(image):\n",
        "    if not isinstance(image, Image.Image):\n",
        "        raise TypeError(\"Input must be a PIL Image.\")\n",
        "\n",
        "    # get the image ready for the model and save it to device\n",
        "    # the processor returns a dictionary\n",
        "    inputs = processor(images=image, return_tensors='pt', padding=True).to(device)\n",
        "\n",
        "    # make it so you don't need to save gradients\n",
        "    with torch.no_grad():\n",
        "        image_features = model.get_image_features(**inputs)\n",
        "\n",
        "    # return the image features, save it to CPU, convert it to a numpy array,\n",
        "    # and flatten it to a vector\n",
        "    return image_features.cpu().numpy().flatten()\n",
        "\n",
        "def image_paths(local_download_path):\n",
        "  file_paths = []\n",
        "\n",
        "  for filename in os.listdir(local_download_path):\n",
        "      if filename.endswith((\"jpg\", \"png\")):\n",
        "          file_paths.append(local_download_path + filename)\n",
        "\n",
        "  return file_paths\n",
        "\n",
        "# the vector db was formed by going through each photo in the drive and embedding it\n",
        "# therefore, we'll take the link to the photo to be its label\n",
        "# the way we can extract the correct band id\n",
        "img_paths = image_paths('/content/drive/MyDrive/Logos/Small_Dataset/')\n",
        "image_embeddings = np.load('/content/drive/MyDrive/Logos/vector_db_correct.npy')\n",
        "labels = img_paths\n",
        "\n",
        "# helper function to strip the band's ID from the file name\n",
        "def id_stripper(file_name, file_path):\n",
        "  band_id = []\n",
        "  i = len(file_path)\n",
        "  while file_name[i] != '_':\n",
        "    band_id.append(file_name[i])\n",
        "    i+=1\n",
        "  return ''.join(band_id)\n",
        "\n",
        "\n",
        "# get the band ids\n",
        "ids = [id_stripper(path, '/content/drive/MyDrive/Logos/Small_Dataset/') for path in img_paths]\n",
        "small_df = pd.DataFrame({})\n",
        "small_df['ID'] = ids\n",
        "small_df['Embedding'] = image_embeddings.tolist()\n",
        "\n",
        "def mean_embedding(group):\n",
        "    return np.mean(np.vstack(group), axis=0)\n",
        "\n",
        "# instead of having an embedding for each image, want to average over all images corresponding to each band\n",
        "mean_df = small_df.groupby('ID')['Embedding'].apply(mean_embedding).reset_index()\n",
        "mean_embeddings = np.vstack(mean_df['Embedding'])\n",
        "mean_labels = mean_df['ID']\n",
        "\n",
        "# now fitting a nearest neighbours model to find the most similar\n",
        "# logo based on cosine similarity\n",
        "nn = NearestNeighbors(n_neighbors = 3, metric = 'cosine')\n",
        "nn.fit(mean_embeddings)\n",
        "\n",
        "def query_new_image(img_path):\n",
        "  new_img_embedding = get_image_embedding(img_path)\n",
        "\n",
        "  _, indices = nn.kneighbors([new_img_embedding])\n",
        "  response = [mean_labels[indices[0][i]] for i in range(3)]\n",
        "  return response\n",
        "\n",
        "#import the dataset\n",
        "bands_df =  pd.read_csv('/content/drive/MyDrive/metal_bands_roster.csv', low_memory=False)\n",
        "\n",
        "# have to add 200 Stab Wounds because they weren't included in the original dataframe\n",
        "SW_200 = { 'Band ID': '3540465014', 'Name': '200 Stab Wounds',\n",
        "          'URL': 'https://www.metal-archives.com/bands/200_Stab_Wounds/3540465014',\n",
        "           'Country': 'United States', 'Genre' : 'Death Metal',\n",
        "           'Status': 'Active', 'Photo_URL' : 'https://www.metal-archives.com/images/3/5/4/0/3540465014_photo.jpg?4349',\n",
        "           'Label ID': '3'}\n",
        "bands_df.loc[len(bands_df)] = SW_200"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxUra4wnNzF2",
        "outputId": "cdde7f32-a110-4712-f0b0-bd7590cd72c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.15.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def gradio_model_guess(query_img):\n",
        "    try:\n",
        "      model_guesses = query_new_image(query_img)\n",
        "      humanized = []\n",
        "      for i in range(3):\n",
        "        id = model_guesses[i]\n",
        "        row = bands_df[bands_df.isin([id]).any(axis=1)]\n",
        "        humanized.append((row['Name'].iloc[0], row['URL'].iloc[0]))\n",
        "      response = (f\"That could be **{humanized[0][0]}**, **{humanized[1][0]}**, or **{humanized[2][0]}**. Here are the links to their Metallum pages for you to check out!\\n\\n\"\n",
        "          f\"[{humanized[0][0]}]({humanized[0][1]})<br> \"\n",
        "          f\"[{humanized[1][0]}]({humanized[1][1]})<br>\"\n",
        "          f\"[{humanized[2][0]}]({humanized[2][1]})\")\n",
        "      return response\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in gradio_model_guess: {e}\")\n",
        "        return str(e)\n",
        "\n",
        "\n",
        "# create the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_model_guess,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Markdown(label=\"Answer Markdown\"),\n",
        "    live=True,\n",
        "    title=\"Band Logo Recognition\",\n",
        "    description=\"Upload a logo image and I'll try to guess which band it belongs to based on my model's predictions.\"\n",
        ")\n",
        "\n",
        "# launch the interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "exTDWk83N0_M",
        "outputId": "e5b59c6c-5bb8-4e08-a194-6f792d5104c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://64759a58dbc0a3fac5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://64759a58dbc0a3fac5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}